{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9963326,"sourceType":"datasetVersion","datasetId":6128736}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from nltk.tokenize import WordPunctTokenizer\nfrom subword_nmt.learn_bpe import learn_bpe\nfrom subword_nmt.apply_bpe import BPE\nimport ast\n\n\ntokenizer = WordPunctTokenizer()\ndef tokenize(x):\n    return ' '.join(tokenizer.tokenize(x.lower()))\ntrain = []\nwith open('/kaggle/input/data-transl/train', 'r') as f, open('train.alien', 'w') as f_src,  open('train.en', 'w') as f_dst:\n  for line in f:\n    train.append(ast.literal_eval(line.strip()))\n    # tokenize the data\n    f_src.write(tokenize(train[-1]['src']) + '\\n')\n    f_dst.write(tokenize(train[-1]['dst']) + '\\n')\n\n# build and apply bpe vocs\nbpe = {}\nfor lang in ['alien', 'en']:\n    learn_bpe(open('./train.' + lang), open('bpe_rules.' + lang, 'w'), num_symbols=8000)\n    bpe[lang] = BPE(open('./bpe_rules.' + lang))\n\n    with open('train.bpe.' + lang, 'w') as f_out:\n        for line in open('train.' + lang):\n            f_out.write(bpe[lang].process_line(line.strip()) + '\\n')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T16:34:15.421425Z","iopub.execute_input":"2024-11-21T16:34:15.422222Z","iopub.status.idle":"2024-11-21T16:35:42.682896Z","shell.execute_reply.started":"2024-11-21T16:34:15.422185Z","shell.execute_reply":"2024-11-21T16:35:42.682200Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 8000/8000 [00:45<00:00, 175.63it/s]\n100%|██████████| 8000/8000 [00:09<00:00, 880.52it/s] \n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"\nval = []\nwith open('/kaggle/input/data-transl/val', 'r') as v, open('val.alien', 'w') as v_src,  open('val.en', 'w') as v_dst:\n  for line in v:\n    val.append(ast.literal_eval(line.strip()))\n    # tokenize the data\n    v_src.write(tokenize(val[-1]['src']) + '\\n')\n    v_dst.write(tokenize(val[-1]['dst']) + '\\n')\n\n# build and apply bpe vocs\nbpe = {}\nfor lang in ['alien', 'en']:\n    learn_bpe(open('./val.' + lang), open('bpe_rules.' + lang, 'w'), num_symbols=8000)\n    bpe[lang] = BPE(open('./bpe_rules.' + lang))\n\n    with open('val.bpe.' + lang, 'w') as v_out:\n        for line in open('val.' + lang):\n            v_out.write(bpe[lang].process_line(line.strip()) + '\\n')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T16:55:24.810770Z","iopub.execute_input":"2024-11-21T16:55:24.811312Z","iopub.status.idle":"2024-11-21T16:55:38.860973Z","shell.execute_reply.started":"2024-11-21T16:55:24.811258Z","shell.execute_reply":"2024-11-21T16:55:38.860171Z"}},"outputs":[{"name":"stderr","text":" 56%|█████▌    | 4454/8000 [00:10<00:07, 464.45it/s]no pair has frequency >= 2. Stopping\n 56%|█████▌    | 4458/8000 [00:10<00:08, 405.74it/s]\n 37%|███▋      | 2960/8000 [00:02<00:03, 1330.44it/s]no pair has frequency >= 2. Stopping\n 38%|███▊      | 3056/8000 [00:02<00:04, 1159.15it/s]\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T16:55:51.167616Z","iopub.execute_input":"2024-11-21T16:55:51.168002Z","iopub.status.idle":"2024-11-21T16:55:51.172727Z","shell.execute_reply.started":"2024-11-21T16:55:51.167969Z","shell.execute_reply":"2024-11-21T16:55:51.171806Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"data_inp = np.array(open('./train.bpe.alien').read().split('\\n'))\ndata_out = np.array(open('./train.bpe.en').read().split('\\n'))\ntrain_out = data_out\ntrain_inp = data_inp\n'''\nfrom sklearn.model_selection import train_test_split\ntrain_inp, dev_inp, train_out, dev_out = train_test_split(data_inp, data_out, test_size=3000,random_state=42)\n'''\nfor i in range(3):\n    print('inp:', train_inp[i])\n    print('out:', train_out[i], end='\\n\\n')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T16:55:59.507575Z","iopub.execute_input":"2024-11-21T16:55:59.507971Z","iopub.status.idle":"2024-11-21T16:56:00.699498Z","shell.execute_reply.started":"2024-11-21T16:55:59.507900Z","shell.execute_reply":"2024-11-21T16:56:00.698570Z"}},"outputs":[{"name":"stdout","text":"inp: ◄▴◓@@ ◠▨ ◨@@ ▽◠▦@@ ◈◬◓▪@@ ▼◬▵\nout: - intri@@ gu@@ ing .\n\ninp: ▽◪@@ ◎◗▦@@ ◫▦◫ ▫▴▨◓◠◓ ▴▫◎◪@@ ▱◫ ◚▴ ◞◧▦@@ ◞▾▢@@ ▱◨▨ ◒◠◓◠@@ ◀@@ ▪▦◈◠▦ ◫◉@@ ◎▴@@ ▱◫▵\nout: he would need to repeat his vo@@ ws in the land of the living and drink from the wine of ages .\n\ninp: ◄▴@@ ◞◠▸@@ ▱◠◓▪@@ ◎◠ ◀◫▱◪ ▼◪◚◠▻ ◚▴◓▴@@ ◎◪@@ ◈◗▦ ◎◫?\nout: you couldn ' t even answer my tex@@ ts ?\n\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"datav_inp = np.array(open('./val.bpe.alien').read().split('\\n'))\ndatav_out = np.array(open('./val.bpe.en').read().split('\\n'))\ndev_out = datav_out\ndev_inp = datav_inp\n'''\nfrom sklearn.model_selection import train_test_split\ntrain_inp, dev_inp, train_out, dev_out = train_test_split(data_inp, data_out, test_size=3000,\n                                                          random_state=42)\n'''\nfor i in range(3):\n    print('inp:', dev_inp[i])\n    print('out:', dev_out[i], end='\\n\\n')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T16:56:05.309705Z","iopub.execute_input":"2024-11-21T16:56:05.310052Z","iopub.status.idle":"2024-11-21T16:56:05.318618Z","shell.execute_reply.started":"2024-11-21T16:56:05.310020Z","shell.execute_reply":"2024-11-21T16:56:05.317633Z"}},"outputs":[{"name":"stdout","text":"inp: ◘@@ ◚ ◞◠▷◫◀◗ ▫◠▨◬◎ ▨◪▦◈@@ ◫▦◫ ▫◧▻@@ ▱◠◈▪ ◚◪ ◝◂@@ ▾@@ ▼@@ ▷◠◓@@ ◈@@ '◬▦ 2@@ 7 : 3@@ 7 '◈▴▨◗ ◕◂▱@@ ◭ ◀◗◓ ▨▴▢ ◈◠▷◠ ◞▨◂◓◨ ▴◒@@ ◗▫@@ ▱◪◈◗▵\nout: the hosts re@@ grou@@ ped , and b@@ ou@@ char@@ d even@@ ed the score again , scor@@ ing a goal with a 27 - 37 man advantage .\n\ninp: ◤@@ ◪▦◫ ▨◠▦@@ ◞▴@@ ◓ ◠◒@@ ▪@@ ◞▪@@ ■ ◀◠◐▪◒@@ ◬▨@@ ▱▪▨ ◞◫◞▫◪◎@@ ◫▦▴ ▨◣▫◭ ▦◫◳@@ ◪▫@@ ▱◗ ▷@@ ▩@@ ▼@@ ◓◪@@ ▱▴◓◫ \"@@ ◕◣◓@@ ◎▴▽@@ ◫\" ◇◐◓@@ ◪▫@@ ▴@@ ◀◫▱@@ ◗◓\nout: a new cancer v@@ acc@@ ine may te@@ ach the im@@ m@@ une system to \" see \" ab@@ nor@@ m@@ al cel@@ ls\n\ninp: ▮@@ ◪@@ ◉@@ ◎▴@@ ▱◫ ◈◪◓◞@@ ▱◪◓ ◧▱◠▦ ◈◗▱ ◈◪◓◞@@ ▱◪◓◗■ ◠◓▫▪▨ ◀◠◐◬◎@@ ◞▪▢ ◂@@ ▨▾▱@@ ▱◠◓▪▦ ◚◪ ◈◫◐▴◓ ◂▨◨▱@@ ▱◠◓▪▦ ◎▩◍@@ ◓◪@@ ◈@@ ◠▫@@ ▱◠◓▪▦◈◠ ◌◪@@ ▶◪@@ ◄@@ ◄ (@@ ◌@@ ▴▦ ◝◗▱@@ ◫◎@@ ▱◪◓@@ ◫■ ▶▴▨@@ ▦@@ ◂▱@@ ◧@@ ▸@@ ◫■ ◄@@ ◭@@ ▷◪@@ ▦◈@@ ◗◞@@ ▱◫▨■ ◄@@ ◠▫◪@@ ◎◠▫◫@@ ▨@@ ) ◈▴◓@@ ◞@@ ▱◪◓◫ ◫▱◪ ▴◒ ◈◪◐@@ ▴◓ ▫▾▫@@ ◨▱@@ ◎◠▨@@ ▫◠@@ ◈▪◓@@ ▵\nout: currently , language sub@@ j@@ ec@@ ts are as popular as science , technology , eng@@ ine@@ ering , and ma@@ them@@ ati@@ cs in the cur@@ ric@@ ul@@ a of independent schools and other e@@ duc@@ ati@@ onal institutions .\n\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"import sys\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\n\nclass Vocab:\n    def __init__(self, tokens, bos=\"_BOS_\", eos=\"_EOS_\", unk='_UNK_', pad='_PAD_'):\n        assert all(tok in tokens for tok in (bos, eos, unk, pad))\n        self.tokens = tokens\n        self.token_to_ix = {t:i for i, t in enumerate(tokens)}\n        self.bos, self.eos, self.unk, self.pad = bos, eos, unk, pad\n        self.bos_ix = self.token_to_ix[bos]\n        self.eos_ix = self.token_to_ix[eos]\n        self.unk_ix = self.token_to_ix[unk]\n        self.pad_ix = self.token_to_ix[pad]  # Индекс для <pad>\n\n    def __len__(self):\n        return len(self.tokens)\n\n    @staticmethod\n    def from_lines(lines, bos=\"_BOS_\", eos=\"_EOS_\", unk='_UNK_', pad='_PAD_'):\n        flat_lines = 'n'.join(list(lines)).split()\n        tokens = sorted(set(flat_lines))\n        tokens = [t for t in tokens if t not in (bos, eos, unk, pad) and len(t)]\n        tokens = [bos, eos, unk, pad] + tokens  # Добавляем <pad> в начало\n        return Vocab(tokens, bos, eos, unk, pad)\n\n    def tokenize(self, string):\n        \"\"\"конвертирует строку в список токенов\"\"\"\n        tokens = [tok if tok in self.token_to_ix else self.unk\n                  for tok in string.split()]\n        return [self.bos] + tokens + [self.eos]\n\n    def to_matrix(self, lines, dtype=torch.int64, max_len=None):\n        \"\"\"\n        конвертирует последовательности токенов переменной длины в фиксированный размер матрицы\n        \"\"\"\n        lines = list(map(self.tokenize, lines))\n        max_len = max_len or max(map(len, lines))\n\n        matrix = torch.full((len(lines), max_len), self.pad_ix, dtype=dtype)  # Используем <pad>\n        for i, seq in enumerate(lines):\n            row_ix = list(map(self.token_to_ix.get, seq))[:max_len]\n            matrix[i, :len(row_ix)] = torch.as_tensor(row_ix)\n\n        return matrix\n\n    def to_lines(self, matrix, crop=True):\n        lines = []\n        for line_ix in map(list,matrix):\n            if crop:\n                if line_ix[0] == self.bos_ix:\n                    line_ix = line_ix[1:]\n                if self.eos_ix in line_ix:\n                    line_ix = line_ix[:line_ix.index(self.eos_ix)]\n            line = ' '.join(self.tokens[i] for i in line_ix if i != self.pad_ix)  # Исключаем <pad>\n            lines.append(line)\n        return lines\n\n    def compute_mask(self, input_ix):\n        return F.pad(torch.cumsum(input_ix == self.eos_ix, dim=-1)[..., :-1] < 1, pad=(1, 0, 0, 0), value=True)\n\n    def get_pad_index(self):\n        return self.pad_ix\ninp_voc = Vocab.from_lines(train_inp)\nout_voc = Vocab.from_lines(train_out)\n#out_voc.get_pad_index('<pad>')\ntgt_pad_index = out_voc.get_pad_index()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T16:56:10.008356Z","iopub.execute_input":"2024-11-21T16:56:10.008700Z","iopub.status.idle":"2024-11-21T16:56:15.237741Z","shell.execute_reply.started":"2024-11-21T16:56:10.008670Z","shell.execute_reply":"2024-11-21T16:56:15.236909Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"# Neural Machine Translation with Transformers\r\n\r\n","metadata":{}},{"cell_type":"code","source":"import math\nimport pandas as pd\nimport torch\nfrom torch import nn\nfrom d2l import torch as d2l\nclass MultiHeadAttention(d2l.Module): \n    def __init__(self, num_hiddens, num_heads, dropout, bias=False, **kwargs):\n        super().__init__()\n        self.num_heads = num_heads\n        self.attention = d2l.DotProductAttention(dropout)\n        self.W_q = nn.LazyLinear(num_hiddens, bias=bias)\n        self.W_k = nn.LazyLinear(num_hiddens, bias=bias)\n        self.W_v = nn.LazyLinear(num_hiddens, bias=bias)\n        self.W_o = nn.LazyLinear(num_hiddens, bias=bias)\n\n    def forward(self, queries, keys, values, valid_lens):\n        queries = self.transpose_qkv(self.W_q(queries))\n        keys = self.transpose_qkv(self.W_k(keys))\n        values = self.transpose_qkv(self.W_v(values))\n\n        if valid_lens is not None:\n            valid_lens = torch.repeat_interleave(\n                valid_lens, repeats=self.num_heads, dim=0)\n\n        output = self.attention(queries, keys, values, valid_lens)\n        output_concat = self.transpose_output(output)\n        return self.W_o(output_concat)\n@d2l.add_to_class(MultiHeadAttention)  #save\ndef transpose_qkv(self, X):\n    X = X.reshape(X.shape[0], X.shape[1], self.num_heads, -1)\n    X = X.permute(0, 2, 1, 3)\n    return X.reshape(-1, X.shape[2], X.shape[3])\n\n@d2l.add_to_class(MultiHeadAttention)\ndef transpose_output(self, X):\n    X = X.reshape(-1, self.num_heads, X.shape[1], X.shape[2])\n    X = X.permute(0, 2, 1, 3)\n    return X.reshape(X.shape[0], X.shape[1], -1)\nclass PositionalEncoding(nn.Module):\n    def __init__(self, num_hiddens, dropout, max_len=1000):\n        super().__init__()\n        self.dropout = nn.Dropout(dropout)\n        self.P = torch.zeros((1, max_len, num_hiddens))\n        X = torch.arange(max_len, dtype=torch.float32).reshape(\n            -1, 1) / torch.pow(10000, torch.arange(\n            0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)\n        self.P[:, :, 0::2] = torch.sin(X)\n        self.P[:, :, 1::2] = torch.cos(X)\n\n    def forward(self, X):\n        X = X + self.P[:, :X.shape[1], :].to(X.device)\n        return self.dropout(X)\nclass PositionWiseFFN(nn.Module):\n    def __init__(self, ffn_num_hiddens, ffn_num_outputs):\n        super().__init__()\n        self.dense1 = nn.LazyLinear(ffn_num_hiddens)\n        self.relu = nn.ReLU()\n        self.dense2 = nn.LazyLinear(ffn_num_outputs)\n\n    def forward(self, X):\n        return self.dense2(self.relu(self.dense1(X)))\n\nclass AddNorm(nn.Module): \n    def __init__(self, norm_shape, dropout):\n        super().__init__()\n        self.dropout = nn.Dropout(dropout)\n        self.ln = nn.LayerNorm(norm_shape)\n\n    def forward(self, X, Y):\n        return self.ln(self.dropout(Y) + X)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T16:56:19.445063Z","iopub.execute_input":"2024-11-21T16:56:19.445510Z","iopub.status.idle":"2024-11-21T16:56:20.910528Z","shell.execute_reply.started":"2024-11-21T16:56:19.445480Z","shell.execute_reply":"2024-11-21T16:56:20.909580Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"## Encoder","metadata":{}},{"cell_type":"code","source":"class TransformerEncoderBlock(nn.Module):  #\n    \n    def __init__(self, num_hiddens, ffn_num_hiddens, num_heads, dropout,\n                 use_bias=False):\n        super().__init__()\n        self.attention = d2l.MultiHeadAttention(num_hiddens, num_heads,\n                                                dropout, use_bias)\n        self.addnorm1 = AddNorm(num_hiddens, dropout)\n        self.ffn = PositionWiseFFN(ffn_num_hiddens, num_hiddens)\n        self.addnorm2 = AddNorm(num_hiddens, dropout)\n\n    def forward(self, X, valid_lens):\n        Y = self.addnorm1(X, self.attention(X, X, X, valid_lens))\n        return self.addnorm2(Y, self.ffn(Y))\n\nclass TransformerEncoder(d2l.Encoder):  #\n    \n    def __init__(self, vocab_size, num_hiddens, ffn_num_hiddens,\n                 num_heads, num_blks, dropout, use_bias=False):\n        super().__init__()\n        self.num_hiddens = num_hiddens\n        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n        self.pos_encoding = d2l.PositionalEncoding(num_hiddens, dropout)\n        self.blks = nn.Sequential()\n        for i in range(num_blks):\n            self.blks.add_module(\"block\"+str(i), TransformerEncoderBlock(\n                num_hiddens, ffn_num_hiddens, num_heads, dropout, use_bias))\n\n    def forward(self, X, valid_lens):\n        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))\n        self.attention_weights = [None] * len(self.blks)\n        for i, blk in enumerate(self.blks):\n            X = blk(X, valid_lens)\n            self.attention_weights[\n                i] = blk.attention.attention.attention_weights\n        return X","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T16:56:25.568125Z","iopub.execute_input":"2024-11-21T16:56:25.568846Z","iopub.status.idle":"2024-11-21T16:56:25.577744Z","shell.execute_reply.started":"2024-11-21T16:56:25.568811Z","shell.execute_reply":"2024-11-21T16:56:25.576798Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"## Decoder","metadata":{}},{"cell_type":"code","source":"class TransformerDecoderBlock(nn.Module):\n    def __init__(self, num_hiddens, ffn_num_hiddens, num_heads, dropout, i):\n        super().__init__()\n        self.i = i\n        self.attention1 = d2l.MultiHeadAttention(num_hiddens, num_heads,\n                                                 dropout)\n        self.addnorm1 = AddNorm(num_hiddens, dropout)\n        self.attention2 = d2l.MultiHeadAttention(num_hiddens, num_heads,\n                                                 dropout)\n        self.addnorm2 = AddNorm(num_hiddens, dropout)\n        self.ffn = PositionWiseFFN(ffn_num_hiddens, num_hiddens)\n        self.addnorm3 = AddNorm(num_hiddens, dropout)\n\n    def forward(self, X, state):\n        enc_outputs, enc_valid_lens = state[0], state[1]\n        if state[2][self.i] is None:\n            key_values = X\n        else:\n            key_values = torch.cat((state[2][self.i], X), dim=1)\n        state[2][self.i] = key_values\n        if self.training:\n            batch_size, num_steps, _ = X.shape\n            # Shape of dec_valid_lens: (batch_size, num_steps), where every\n            \n            dec_valid_lens = torch.arange(\n                1, num_steps + 1, device=X.device).repeat(batch_size, 1)\n        else:\n            dec_valid_lens = None\n        # Self-attention\n        X2 = self.attention1(X, key_values, key_values, dec_valid_lens)\n        Y = self.addnorm1(X, X2)\n        # Encoder-decoder attention. \n        Y2 = self.attention2(Y, enc_outputs, enc_outputs, enc_valid_lens)\n        Z = self.addnorm2(Y, Y2)\n        return self.addnorm3(Z, self.ffn(Z)), state\n\nclass TransformerDecoder(d2l.AttentionDecoder):\n    def __init__(self, vocab_size, num_hiddens, ffn_num_hiddens, num_heads,\n                 num_blks, dropout):\n        super().__init__()\n        self.num_hiddens = num_hiddens\n        self.num_blks = num_blks\n        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n        self.pos_encoding = d2l.PositionalEncoding(num_hiddens, dropout)\n        self.blks = nn.Sequential()\n        for i in range(num_blks):\n            self.blks.add_module(\"block\"+str(i), TransformerDecoderBlock(\n                num_hiddens, ffn_num_hiddens, num_heads, dropout, i))\n        self.dense = nn.LazyLinear(vocab_size)\n\n    def init_state(self, enc_outputs, enc_valid_lens):\n        return [enc_outputs, enc_valid_lens, [None] * self.num_blks]\n\n    def forward(self, X, state):\n        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))\n        self._attention_weights = [[None] * len(self.blks) for _ in range (2)]\n        for i, blk in enumerate(self.blks):\n            X, state = blk(X, state)\n            # Decoder self-attention weights\n            self._attention_weights[0][\n                i] = blk.attention1.attention.attention_weights\n            # Encoder-decoder attention weights\n            self._attention_weights[1][\n                i] = blk.attention2.attention.attention_weights\n        return self.dense(X), state\n\n    @property\n    def attention_weights(self):\n        return self._attention_weights","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T16:56:29.555620Z","iopub.execute_input":"2024-11-21T16:56:29.555974Z","iopub.status.idle":"2024-11-21T16:56:29.568061Z","shell.execute_reply.started":"2024-11-21T16:56:29.555912Z","shell.execute_reply":"2024-11-21T16:56:29.566996Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# Define the device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Convert data to tensors and move to device\ntrain_inp_tensor = inp_voc.to_matrix(train_inp).to(device)\ntrain_out_tensor = out_voc.to_matrix(train_out).to(device)\n\ndev_inp_tensor = inp_voc.to_matrix(dev_inp).to(device)\ndev_out_tensor = out_voc.to_matrix(dev_out).to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T17:04:49.508652Z","iopub.execute_input":"2024-11-21T17:04:49.509032Z","iopub.status.idle":"2024-11-21T17:05:05.774298Z","shell.execute_reply.started":"2024-11-21T17:04:49.509000Z","shell.execute_reply":"2024-11-21T17:05:05.773305Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# Create DataLoader for training and validation\nfrom torch.utils.data import DataLoader, TensorDataset\ntrain_dataset = TensorDataset(train_inp_tensor, train_out_tensor)\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n\ndev_dataset = TensorDataset(dev_inp_tensor, dev_out_tensor)\ndev_loader = DataLoader(dev_dataset, batch_size=32, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T17:05:44.244676Z","iopub.execute_input":"2024-11-21T17:05:44.245354Z","iopub.status.idle":"2024-11-21T17:05:44.251870Z","shell.execute_reply.started":"2024-11-21T17:05:44.245319Z","shell.execute_reply":"2024-11-21T17:05:44.250890Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nclass TransformerModel(nn.Module):\n    def __init__(self, inp_voc, out_voc, num_hiddens, ffn_num_hiddens, num_heads, num_blks, dropout):\n        super(TransformerModel, self).__init__()\n        self.encoder = TransformerEncoder(len(inp_voc), num_hiddens, ffn_num_hiddens, num_heads, num_blks, dropout)\n        self.decoder = TransformerDecoder(len(out_voc), num_hiddens, ffn_num_hiddens, num_heads, num_blks, dropout)\n        self.out_voc = out_voc\n\n    def forward(self, inp, out):\n        enc_outputs = self.encoder(inp, None)\n        dec_state = self.decoder.init_state(enc_outputs, None)\n        return self.decoder(out, dec_state)\n'''\n# Параметры модели\nsrc_vocab_size = len(inp_voc)  # Размер словаря исходного языка\ntgt_vocab_size = len(out_voc)  # Размер словаря целевого языка\nembedding_dim = 512           # Размер векторного представления\nn_heads = 8             # Количество голов в многоглавом внимании\nnum_encoder_layers = 6  # Количество слоев кодировщика\nnum_decoder_layers = 6  # Количество слоев декодировщика\nnum_blks = 6   # количество блоков (слоев) в энкодере и декодере\ndropout_rate = 0.1  # вероятность дропаута\n'''\n\nnum_hiddens = 512\nffn_num_hiddens = 2048\nnum_heads = 8\nnum_blks = 6\ndropout = 0.1\n\nmodel = TransformerModel(inp_voc, out_voc, num_hiddens, ffn_num_hiddens, num_heads, num_blks, dropout).to(device)\n# Оптимизатор и функция потерь\ncriterion = nn.CrossEntropyLoss(ignore_index=out_voc.get_pad_index())\noptimizer = optim.Adam(model.parameters(), lr=0.0001)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T17:15:34.396894Z","iopub.execute_input":"2024-11-21T17:15:34.397684Z","iopub.status.idle":"2024-11-21T17:15:35.595138Z","shell.execute_reply.started":"2024-11-21T17:15:34.397650Z","shell.execute_reply":"2024-11-21T17:15:35.594201Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# Training loop\ndef train(model, train_loader, criterion, optimizer, num_epochs=10):\n    model.train()\n    for epoch in range(num_epochs):\n        total_loss = 0\n        for inp, out in train_loader:\n            inp.to(device), out.to(device)\n            optimizer.zero_grad()\n            out_pred, _ = model(inp, out[:, :-1])\n            loss = criterion(out_pred.permute(0, 2, 1), out[:, 1:])\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n        print(f'Epoch {epoch+1}, Loss: {total_loss/len(train_loader)}')\n        # Save the model after each epoch\n        torch.save(model.state_dict(), f'../working/model_epoch_{epoch+1}.pth')\n\n\n# Validation loop\ndef validate(model, dev_loader, criterion):\n    model.eval()\n    total_loss = 0\n    with torch.no_grad():\n        for inp, out in dev_loader:\n            inp, out = inp.to(device), out.to(device)\n            out_pred, _ = model(inp, out[:, :-1])\n            loss = criterion(out_pred.permute(0, 2, 1), out[:, 1:])\n            total_loss += loss.item()\n    print(f'Validation Loss: {total_loss/len(dev_loader)}')\n\n\n\ntrain(model, train_loader, criterion, optimizer, num_epochs=10)\n\nvalidate(model, dev_loader, criterion)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T17:26:11.546517Z","iopub.execute_input":"2024-11-21T17:26:11.547115Z"}},"outputs":[{"name":"stdout","text":"Epoch 1, Loss: 4.089727184096345\nEpoch 2, Loss: 3.400566702969245\nEpoch 3, Loss: 3.019813317144385\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}